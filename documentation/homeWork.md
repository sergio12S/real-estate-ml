# Data preprocessing
1. Label Encoding

2. One-hot encoding

3. Scalling

4. Feature engineering

5. Polynomial transformation

6. Power transforms

7. Binning

# Developing model
1. Voiting and averaging

2. Bagging

3. Boosting

4. Stacking

Bagging, Boosting уменьшают дисперсию оценки, посколько они объеденяют несколько оценок из разных моделей. Благодарю этому получается результат с более высокой точностью.
Если модель имеет низкую точность,  то смещение которое происходит в bagging обычно не приводит к хорошим результатам. 
В это же время boosting создает комбинированную модель с меньшими ошибками, поскольку они оптимизирует преимущества самих же моделей внутри.
В отличие от Bagging, Boosting определяет веса моделей, чтобы дать веса более лучшим ученикам. 
Оба алгоритма уменьшает дисперсию, но только Boosting уменьшает смещение.
Boosting более подвержен переобучению.

Оба модели берет случайную выборку, но это же и приводит к утечки памяти.